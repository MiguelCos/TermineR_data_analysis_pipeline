---
title: "TermineR Exploratory Analysis"
author: "Your Name"
format:
  html:
    code-fold: true
    code-summary: "Show the code"
    toc: true
    toc-depth: 3
    number-sections: false
    embed-resources: true
    df-print: paged
    max-width: "1200px"
editor: source
execute:
  eval: true
  echo: false
  error: false
  warning: false
  message: false
  cache: true
---

# Setup and Parameters

```{r setup}
#| cache: false
# Load required libraries
suppressPackageStartupMessages({
  library(TermineR)
  library(tidyverse)
  library(here)
  library(arrow)
  library(SummarizedExperiment)
  library(ggpubr)
  library(pheatmap)
  library(RColorBrewer)
  library(mixOmics)
  library(naniar)
  library(kableExtra)
  library(janitor)
  library(sva)
})


# Set options
options(max.print = 1000, scipen = 999, stringsAsFactors = FALSE)

# Source helper functions
source(here("scr/modif_diann_adapter.R"))
source(here("scr/helper_functions.R"))

# Create results directories
dir.create(here("results"), showWarnings = FALSE, recursive = TRUE)
dir.create(here("rds"), showWarnings = FALSE, recursive = TRUE)
rds_dir <- here("rds")
```

```{r define_parameters}
#| cache: false
# === SEARCH ENGINE CONFIGURATION ===
search_engine <- "fragpipe_tmt"  # Options: "diann", "fragpipe_tmt", "fragpipe_lf", "fragpipe_heavy_light", "spectronaut"

# === DATA LOCATIONS (adjust based on search engine) ===
# For DIA-NN
diann_report_location <- here("initial_data/report.parquet")  # Can be .parquet or .tsv

# For FragPipe TMT
fragpipe_parent_dir <- here("data/2024_05_semi_tryptic_search_fp21")  # Directory containing mix folders

# For FragPipe Label-Free
fragpipe_lf_parent_dir <- here("initial_data/fragpipe_lf_search")
fragpipe_lf_annotation <- here("initial_data/fragpipe_lf_annotation.txt")

# For FragPipe Heavy-Light
fragpipe_hl_file <- here("initial_data/combined_modified_peptide_label_quant.tsv")
fragpipe_hl_annotation <- here("initial_data/fragpipe_hl_annotation.txt")

# For Spectronaut
spectronaut_report <- here("initial_data/spectronaut_report.tsv")

# Common files
location_annotation <- here("data/2024_05_semi_tryptic_search_fp21/experiment_annotation.tsv")
fasta_location <- here("data/ebi_mus_musculus_canonical_proteome_1gene_1protein_2023_03_release_plus_irts.fasta")
targetp_location <- here("data/mouse_uniprot_summary.targetp2")  # Set to NULL if not available

# === EXPERIMENTAL PARAMETERS ===
sense_protease <- "C"  # "C" for C-terminal cleavage (trypsin), "N" for N-terminal
specificity_protease <- "K|R"  # Trypsin specificity
organism_annotation <- "mouse"  # Options: "human", "mouse", "arabidopsis", etc.
instrument <- "MBL"  # Instrument prefix in sample names

# === SEARCH ENGINE SPECIFIC PARAMETERS ===
# FragPipe TMT parameters
ref_sample <- "norm"  # Reference channel for TMT normalization
min_purity <- 0.5  # Minimum PSM purity
tmt_delta <- "229"  # TMT delta mass ("229" for TMT10/11, "304" for TMT16)

# DIA-NN parameters
proteotypic_only <- TRUE  # Use only proteotypic peptides
summarization_method <- "SUM"  # "SUM" or "MAX" for precursor summarization

# === ANALYSIS PARAMETERS ===
missing_accepted <- 2 / 4  # Max missing values per condition (2 out of 4 replicates)
pre_fix <- "terminer_analysis_"  # Prefix for output files

# === PLOT PARAMETERS ===
plot_width <- 10
plot_height <- 10
side_by_side_scale <- 2.0  # wider figures when arranging multiple plots
plot_dpi <- 300

# Interest scope for PCA
interesting_specificity <- c("^semi")
interesting_nterm_modif <- c("n", "Acetyl", "TMT")  # e.g., c("Dimethyl")

# Toggle: if TRUE, PCA will use only 'interesting' features (per add_interest_flags)
pca_use_interest_only <- FALSE
# Set to TRUE to restrict PCA to semi-specific features optionally filtered by N-term mods above
```

```{r interest_scope_helpers}
#| cache: false
# Helper to add interest flags to a data.frame of peptide annotations
add_interest_flags <- function(df,
                              specificity_patterns = interesting_specificity,
                              nterm_mod_patterns = interesting_nterm_modif) {
  # Specificity regex
  spec_ok <- if (is.null(specificity_patterns) || length(specificity_patterns) == 0) {
    rep(TRUE, nrow(df))
  } else {
    stringr::str_detect(dplyr::coalesce(df$specificity, ""),
                        paste0("(?:", paste(specificity_patterns, collapse = ")|("), ")"))
  }
  # N-term mod patterns
  nterm_vec <- if ("nterm_modif" %in% names(df)) df$nterm_modif else if ("nterm_modification" %in% names(df)) df$nterm_modification else if ("nterm_modif_peptide" %in% names(df)) df$nterm_modif_peptide else rep(NA_character_, nrow(df))
  nterm_ok <- if (is.null(nterm_mod_patterns) || length(nterm_mod_patterns) == 0) {
    rep(TRUE, nrow(df))
  } else {
    stringr::str_detect(dplyr::coalesce(as.character(nterm_vec), ""),
                        paste0("(?:", paste(nterm_mod_patterns, collapse = ")|("), ")"))
  }
  # Flags
  is_semi_specific <- stringr::str_detect(dplyr::coalesce(df$specificity, ""), "^semi")
  is_nterm_mod_of_interest <- if (is.null(nterm_mod_patterns) || length(nterm_mod_patterns) == 0) rep(FALSE, nrow(df)) else nterm_ok
  is_in_scope_for_interest <- if (is.null(nterm_mod_patterns) || length(nterm_mod_patterns) == 0) is_semi_specific else (is_semi_specific & nterm_ok)
  proc_col <- if ("processing_type" %in% names(df)) "processing_type" else if ("processing_type" %in% names(df)) "processing_type" else NULL
  is_not_canonical <- if (!is.null(proc_col)) dplyr::coalesce(df[[proc_col]], "") == "not_canonical" else rep(NA, nrow(df))
  df %>% dplyr::mutate(
    is_semi_specific = is_semi_specific,
    is_nterm_mod_of_interest = is_nterm_mod_of_interest,
    is_in_scope_for_interest = is_in_scope_for_interest,
    is_not_canonical = is_not_canonical
  )
}
```

# Data Loading and Annotation

```{r load_data}
#| cache: true
# Load data based on search engine
rds_path_data <- file.path(rds_dir, paste0(search_engine, "_data.rds"))

if (file.exists(rds_path_data)) {

  message("Loading cached ", search_engine, " data...")
  df_from_search <- read_rds(rds_path_data)
  
} else {
  message("Loading ", search_engine, " data...")
  
  # Load data based on search engine type
  df_from_search <- switch(search_engine,
    "diann" = {
      # DIA-NN data loading
      file_ext <- tools::file_ext(diann_report_location)
      
      if (file_ext == "parquet") {
        message("Using parquet adapter for DIA-NN report.parquet file...")
        diann_adapter_parquet(
          path_to_file = diann_report_location,
          proteotypic = proteotypic_only,
          summarization = summarization_method
        )
      } else if (file_ext == "tsv") {
        message("Using standard diann_adapter for DIA-NN report.tsv file...")
        result <- diann_adapter(
          path_to_file = diann_report_location,
          proteotypic = proteotypic_only,
          summarization = summarization_method
        )
        # Clean column names for TSV files
        result %>% rename_with(~ str_remove(., "_.*"), starts_with(instrument))
      } else {
        stop("Unsupported DIA-NN file format. Please use either .parquet or .tsv files.")
      }
    },
    
    "fragpipe_tmt" = {
      message("Using FragPipe TMT adapter...")
      fragpipe_adapter(
        parent_dir = fragpipe_parent_dir,
        ref_sample = ref_sample,
        grouping_var = "nterm_modif_peptide",
        min_purity = min_purity,
        tmt_delta = tmt_delta
      )
    },
    
    "fragpipe_lf" = {
      message("Using FragPipe Label-Free adapter...")
      fragpipe_lf_adapter(
        parent_dir = fragpipe_lf_parent_dir,
        annotation_file_path = fragpipe_lf_annotation,
        grouping_var = "nterm_modif_peptide"
      )
    },
    
    "fragpipe_heavy_light" = {
      message("Using FragPipe Heavy-Light adapter...")
      fragpipe_dda_heavy_light_adapter(
        combined_modified_peptide_file = fragpipe_hl_file,
        annotation_file_path = fragpipe_hl_annotation,
        grouping_var = "nterm_modif_peptide"
      )
    },
    
    "spectronaut" = {
      message("Using Spectronaut adapter...")
      spectronaut_adapter(
        path_to_file = spectronaut_report,
        proteotypic = proteotypic_only
      )
    },
    
    stop("Unsupported search engine: ", search_engine, 
         ". Supported options: diann, fragpipe_tmt, fragpipe_lf, fragpipe_heavy_light, spectronaut")
  )
  
  write_rds(df_from_search, rds_path_data)
}

# Load experimental design (adapt based on search engine)
if (search_engine %in% c("fragpipe_lf", "fragpipe_heavy_light")) {
  # For FragPipe LF and Heavy-Light, experimental design is handled internally
  experimental_design <- tribble(
    ~sample, ~condition, ~bio_replicate,
    # This will be populated based on the specific adapter used
  )
  message("Experimental design extracted from FragPipe adapter results")
} else {
  # For other search engines, load external annotation file
  experimental_design <- read_delim(location_annotation) %>%
    filter(
      condition != "empty",
      condition != "norm") %>%
    mutate(
      sample_name = str_remove(sample_name, "_.*"),
      condition = str_remove(
        sample,
        "^[^_]*_"
      )
    ) %>% 
    separate(
      condition,
      into = c("treatment", "time"),
      sep = "_",
      remove = FALSE
    ) 
}

# Load protein to gene mapping (adapt based on search engine and data availability)
if (search_engine == "diann" && file.exists(diann_report_location)) {
  prot2gene <- arrow::open_dataset(diann_report_location) %>%
    dplyr::select(protein = Protein.Ids, gene = Genes) %>%
    collect() %>%
    distinct() %>%
    separate_rows(gene, sep = ",") %>%
    distinct()

} else if (search_engine %in% c("fragpipe_tmt", "fragpipe_lf")) {
  # For FragPipe, look for PSM files
  message("Looking for FragPipe PSM files for protein-to-gene mapping...")
  
  # Determine parent directory based on search engine
  parent_dir <- if (search_engine == "fragpipe_tmt") fragpipe_parent_dir else fragpipe_lf_parent_dir
  
  # Find all psm.tsv files
  psm_files <- list.files(parent_dir, pattern = "psm\\.tsv$", recursive = TRUE, full.names = TRUE)
  
  if (length(psm_files) > 0) {
    message("Found ", length(psm_files), " PSM files. Reading protein mapping...")
    
    # Read and combine protein mapping from all PSM files
    prot2gene <- map_dfr(psm_files, ~{
      tryCatch({
        read_tsv(.x, show_col_types = FALSE) %>%
          dplyr::select(
            protein = `Protein ID`,
            entry_name = `Entry Name`,
            gene = Gene,
            protein_description = `Protein Description`
          ) %>%
          distinct()
      }, error = function(e) {
        message("Warning: Could not read ", .x, " - ", e$message)
        return(tibble())
      })
    }) %>%
    distinct() %>%
    # Clean up gene names and create final mapping
    mutate(
      gene = case_when(
        !is.na(gene) & gene != "" ~ gene,
        !is.na(entry_name) & entry_name != "" ~ entry_name,
        TRUE ~ protein
      )
    ) %>%
    dplyr::select(protein, gene, entry_name, protein_description) %>%
    distinct()
    
    message("Extracted protein-to-gene mapping for ", nrow(prot2gene), " proteins")

  } else {

    message("No PSM files found. Using protein IDs as gene names.")
    prot2gene <- df_from_search %>%
      dplyr::select(protein) %>%
      distinct() %>%
      mutate(gene = protein) %>%
      dplyr::select(protein, gene)
  }
} else {

  # For other search engines, create basic mapping from available data
  prot2gene <- df_from_search %>%
    dplyr::select(protein) %>%
    distinct() %>%
    mutate(gene = protein) %>%  # Fallback: use protein ID as gene name
    dplyr::select(protein, gene)
  
  message("Using protein IDs as gene names. Consider adding gene mapping for better annotation.")
}
```

```{r annotate_peptides}
#| cache: true
# Annotate neo-termini
rds_path_annotated <- file.path(rds_dir, "annotated_data.rds")

if (file.exists(rds_path_annotated)) {

  message("Loading cached annotated data...")
  annotated_df_quant <- read_rds(rds_path_annotated)
  # Ensure flags exist even when loading from cache
  annotated_df_quant <- add_interest_flags(annotated_df_quant)

} else {
  message("Annotating neo-termini...")

  annotated_df_quant <- annotate_neo_termini(
    peptides_df = df_from_search,
    fasta_location = fasta_location,
    sense = sense_protease,
    specificity = specificity_protease,
    organism = organism_annotation
  ) %>% 
    mutate(cleav_len = nchar(cleavage_sequence)) %>% 
    relocate(cleav_len, .after = processing_annotation_end) %>%
    filter(!is.na(peptide_start))
  
  # Add TargetP annotation if available
  if (is.null(targetp_location)) {

    message("TargetP annotation not defined")
  } else {
    message("TargetP annotation defined. Loading")

  targetp_annotation_df <- read_tsv(targetp_location,
                               skip = 1) %>%
  clean_names() %>%
  separate(
    number_id,
    into = c("trembl", "protein", "uniprot_accession"),
    sep = "\\|",
    remove = FALSE
  ) %>%
  dplyr::rename(
    protein_header = number_id
  ) %>%
  mutate(
    targetp_p1_position = str_remove(cs_position,
                                     "CS pos:")
  ) %>%
  mutate(
    targetp_p1_position = str_remove(targetp_p1_position,
                                     # everything after the first "-"
                                     "-.*")
  ) %>%
  mutate(
    targetp_p1_position = as.numeric(targetp_p1_position)
  ) %>%
  filter(
    !is.na(targetp_p1_position)
  ) %>% 
  dplyr::select(
    protein,
    targetp_category = prediction,
    targetp_p1_position
  ) 
    
  annotated_df_quant <- annotated_df_quant %>%
    left_join(., targetp_annotation_df) %>%
    relocate(
      cleav_len,
      .after = cleavage_sequence
    ) %>%
    mutate(
      targetp_matches_p1_prime = case_when(
        abs(as.numeric(p1_position) - targetp_p1_position) < 4 ~ TRUE,
          TRUE ~ FALSE
      )
    ) %>%
    mutate(
      processing_type_targetp = case_when(
        targetp_matches_p1_prime == TRUE & targetp_category == "SP" ~ "SIGNAL",
        targetp_matches_p1_prime == TRUE & targetp_category == "mTP" ~ "mTP",
        targetp_matches_p1_prime == TRUE & targetp_category == "cTP" ~ "cTP",
        targetp_matches_p1_prime == TRUE & targetp_category == "luTP" ~ "luTP",
        targetp_matches_p1_prime == FALSE ~ "not_canonical",
        is.na(targetp_matches_p1_prime) ~ "not_canonical",
        TRUE ~ "not_canonical"
      )) %>%
    mutate(
      processing_type_terminer = dplyr::case_when(
        processing_type_targetp != "not_canonical" ~ processing_type_targetp,
        TRUE ~ dplyr::coalesce(uniprot_processing_type, "not_canonical_no_procc_annot")
      )
    ) %>%
    mutate(
      source_processing_annotation = case_when(
        (uniprot_processing_type == processing_type_targetp) & (uniprot_processing_type == "not_canonical") ~ "Other",
        (uniprot_processing_type == processing_type_targetp) & (processing_type_targetp == "not_canonical") ~ "Other",
        (uniprot_processing_type == processing_type_targetp) & (uniprot_processing_type == "not_canonical_no_procc_annot") ~ "Other",
        (uniprot_processing_type != processing_type_targetp) &  (uniprot_processing_type == "not_canonical") ~ "TargetP",
        (uniprot_processing_type != processing_type_targetp) &  (processing_type_targetp == "not_canonical") ~ "Uniprot",
        (uniprot_processing_type != processing_type_targetp) &  (uniprot_processing_type == "not_canonical_no_procc_annot") ~ "Other",
        (uniprot_processing_type != processing_type_targetp) &  (uniprot_processing_type != "not_canonical") ~ "Conflict/both",
        (uniprot_processing_type != processing_type_targetp) &  (uniprot_processing_type != "not_canonical_no_procc_annot") ~ "Conflict/both",
        (uniprot_processing_type != processing_type_targetp) &  (processing_type_targetp != "not_canonical") ~ "Conflict/both",
        TRUE ~ "not_canonical"
      )
    ) %>%
    mutate(
      source_processing_annotation = case_when(
        str_detect(processing_type_terminer, "not_canonical") ~ "Other", 
        TRUE ~ source_processing_annotation
      )) %>%
    mutate(
      processing_type = case_when(
        str_detect(processing_type_terminer, "INIT_MET") ~ "P2",
        processing_type_terminer == "Intact_ORF" ~ "P1",
        processing_type_terminer == "mTP" ~ "MTS", 
        processing_type_terminer == "SIGNAL" ~ "SP",
        processing_type_terminer == "not_canonical_no_procc_annot" ~ "not_canonical",
        TRUE ~ processing_type_terminer
      )
    ) %>%
    mutate(
      difference = case_when(
        targetp_matches_p1_prime == TRUE ~ p1_position - targetp_p1_position,
        matches_p1_prime == TRUE & targetp_matches_p1_prime == FALSE ~ p1_position - processing_annotation_end
      )
    ) %>%
    mutate(
      processing_type = factor(
        processing_type,
        levels = c("P1", "P2", "SP", "MTS", "cTP", "TRANSIT", "PROPEP", "not_canonical")
      )
    ) %>%
    relocate(targetp_category,
             targetp_p1_position,
             targetp_matches_p1_prime,
             processing_type_targetp,
             processing_type_terminer,
             processing_type,
             source_processing_annotation,
             .after = processing_annotation_end) 
  
  }  # Close 'else' for targetp_location
  
  # Add flags before caching
  annotated_df_quant <- add_interest_flags(annotated_df_quant)
  
  write_rds(annotated_df_quant, rds_path_annotated)
}
```

# Identification Statistics

```{r identification_stats}
#| fig-width: !expr plot_width
#| fig-height: !expr plot_height
#| cache: true

# Calculate identification statistics
create_identification_plots <- function(data, experimental_design) {

  # Number of identifications per sample
  ids_per_sample <- data %>%
    dplyr::select(starts_with(instrument)) %>%
    pivot_longer(cols = starts_with(instrument), names_to = "sample", values_to = "value") %>%
    group_by(sample) %>%
    summarise(n_identifications = sum(!is.na(value)), .groups = 'drop') %>%
    left_join(experimental_design, by = "sample")
  
  # Plot identifications by condition
  p1 <- ids_per_sample %>%
    ggplot(aes(x = sample, y = n_identifications, fill = condition)) +
    geom_col(position = "dodge") +
    labs(title = "Number of Identifications by Condition",
         x = "Condition", y = "Number of Identifications") +
    theme_minimal() +
    theme(
      legend.position = "none",
      axis.text.x = element_text(angle = 90, hjust = 1),
      )
  
  return(list(plot = p1, data = ids_per_sample))
}

id_results <- create_identification_plots(annotated_df_quant, experimental_design)
print(id_results$plot)
```

# Median Identifications by Processing Type

```{r median_ids_processing_type}
#| fig-width: !expr plot_width
#| fig-height: !expr plot_height
#| cache: true

# Calculate identifications by specificity and refined processing type (excluding specific peptides)
ids_by_specificity_refined <- annotated_df_quant %>%
  filter(specificity %in% c("semi_Cterm", "semi_Nterm")) %>%
  dplyr::select(specificity, processing_type, starts_with(instrument)) %>%
  pivot_longer(cols = starts_with(instrument),
               names_to = "sample",
               values_to = "value") %>%
  group_by(specificity, processing_type, sample) %>%
  summarise(n_identifications = sum(!is.na(value)), .groups = 'drop') %>%
  left_join(
    experimental_design, 
    by = "sample")

# Calculate median identifications by refined processing type
median_ids_refined_processing <- ids_by_specificity_refined %>%
  group_by(specificity, processing_type, condition) %>%
  summarise(
    median_ids = median(n_identifications),
    mean_ids = mean(n_identifications),
    sd_ids = sd(n_identifications),
    n_samples = n(),
    .groups = 'drop'
  )

# Plot median identifications with facet_grid (horizontal bars)
plot_median_refined <- median_ids_refined_processing %>%
  ggplot(aes(x = median_ids, 
             y = condition,
             fill = condition)) +
  geom_col() +
  geom_errorbar(aes(xmin = median_ids - sd_ids, 
                    xmax = median_ids + sd_ids),
                width = 0.3, alpha = 0.7) +
  geom_text(aes(label = round(median_ids, 0)), 
            hjust = -0.01, vjust = -0.2, size = 2.5) +
  facet_grid(processing_type ~ specificity, scales = "free_x") +
  scale_x_continuous(expand = expansion(mult = c(0, 0.1))) +
  labs(
    title = "Median Number of Identifications by Refined Processing Type",
    subtitle = "Semi-specific peptides only, grouped by specificity and processing type",
    x = "Median number of identifications",
    y = "Condition",
    fill = "Condition"
  ) +
  theme_minimal() +
  theme(
    axis.text.y = element_text(angle = 0, hjust = 1),
    legend.position = "bottom",
    strip.text = element_text(size = 9)
  )

print(plot_median_refined)

# Display summary table
knitr::kable(median_ids_refined_processing, 
             caption = "Summary Statistics: Identifications by Refined Processing Type and Condition",
             digits = 1) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))
```

# Missing Values Analysis

```{r missing_values}
#| fig-width: !expr plot_width
#| fig-height: !expr plot_height
#| cache: true

# Analyze missing value patterns
missing_analysis <- annotated_df_quant %>%
  dplyr::select(starts_with(instrument)) %>%
  vis_miss(warn_large_data = FALSE) +
  labs(title = "Missing Value Patterns")

print(missing_analysis)

# Calculate missing value statistics
missing_stats <- annotated_df_quant %>%
  dplyr::select(starts_with(instrument)) %>%
  summarise_all(~sum(is.na(.))) %>%
  pivot_longer(everything(), names_to = "sample", values_to = "missing_count") %>%
  left_join(experimental_design, by = "sample")

missing_plot <- missing_stats %>%
  ggplot(aes(x = sample, y = missing_count, fill = condition)) +
  geom_col() +
  labs(title = "Missing Values by Sample", x = "Sample", y = "Missing Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

print(missing_plot)
```

# Imputation and Data Preparation

```{r imputation}
#| cache: true

# Prepare data for downstream analysis
rds_path_prepared <- file.path(rds_dir, "prepared_data.rds")

if (file.exists(rds_path_prepared)) {

  message("Loading cached prepared data...")
  se_pept_imp_raw <- read_rds(rds_path_prepared)

} else {
  message("Preparing data...")
  
  # Create quantification matrix
  quant_matrix <- annotated_df_quant %>%
    dplyr::select(nterm_modif_peptide, starts_with(instrument)) %>%
    column_to_rownames("nterm_modif_peptide") %>%
    # make sure that the order of the columns in quant_matrix matches the order in sample experimental_design
    dplyr::select(all_of(experimental_design$sample)) %>%
    as.matrix()
  
  # For TMT data, work only with features present in all samples
  if (search_engine == "fragpipe_tmt") {

    message("TMT data detected: filtering for complete cases only...")
    complete_features <- complete.cases(quant_matrix)
    quant_matrix <- quant_matrix[complete_features, ]
    
    # Filter annotation data to match
    annotation_data <- annotated_df_quant %>%
      filter(nterm_modif_peptide %in% rownames(quant_matrix)) %>%
      # force the order of the rows to match the quant_matrix
      dplyr::arrange(match(nterm_modif_peptide, rownames(quant_matrix))) %>%
      dplyr::select(-starts_with(instrument))
    
    message("Retained ", nrow(quant_matrix), " complete features out of ", 
            nrow(annotated_df_quant), " total features")

  } else {

    # For other data types, perform imputation as before
    message("Non-TMT data: performing imputation...")
    annotation_data <- annotated_df_quant %>%
      dplyr::select(-starts_with(instrument))
  }
  
  # Create SummarizedExperiment object
  se_pept_imp_raw <- SummarizedExperiment(
    assays = list(counts = quant_matrix),
    colData = experimental_design,
    rowData = annotation_data
  )
  
  # Apply imputation only for non-TMT data
  if (search_engine != "fragpipe_tmt") {
    se_pept_imp_raw <- terminer_imputation(
      se = se_pept_imp_raw,
      min_fraction_condition = missing_accepted,
      min_fraction_replicate = 0.5,
      min_n_peptides = 1
    )
  }
  
  write_rds(se_pept_imp_raw, rds_path_prepared)
}
```

# Principal Component Analysis

```{r pca_analysis_1}
#| fig-width: !expr plot_width
#| fig-height: !expr plot_height
#| cache: true

perform_pca_analysis <- function(se_object, title_suffix = "", subtitle = "Visualizing conditions", color_var = "condition") {
  pca_matrix <- assay(se_object) %>% t() %>% na.omit()
  
  pca_result <- prcomp(pca_matrix, scale. = TRUE)
  
  pca_df <- data.frame(
    sample = rownames(pca_result$x),
    PC1 = pca_result$x[,1],
    PC2 = pca_result$x[,2]
  ) %>%
    left_join(experimental_design, by = "sample")
  
  var_exp <- summary(pca_result)$importance[2,]
  
  pca_plot <- pca_df %>%
    ggplot(aes(x = PC1, y = PC2, color = .data[[color_var]])) +
    geom_point(size = 5) +
    #stat_ellipse(level = 0.68) +
    labs(
      title = paste("PCA Analysis", title_suffix),
      subtitle = subtitle,
      x = paste("PC1 -", round(var_exp[1] * 100, 1), "% variance"),
      y = paste("PC2 -", round(var_exp[2] * 100, 1), "% variance"),
      color = str_to_title(str_replace_all(color_var, "_", " "))
    ) +
    theme_minimal()
  
  return(list(plot = pca_plot, data = pca_df, variance = var_exp))
}

# Optional subsetting for PCA
se_for_pca <- if (isTRUE(pca_use_interest_only)) {
  keep <- rowData(se_pept_imp_raw)$is_in_scope_for_interest
  keep[is.na(keep)] <- FALSE
  se_pept_imp_raw[keep, , drop = FALSE]
} else {
  se_pept_imp_raw
}

pca_results_1 <- perform_pca_analysis(
  se_for_pca, 
  title_suffix = "- Before Batch Correction",
  subtitle = if (isTRUE(pca_use_interest_only)) "PCA on interesting features" else "Visualizing conditions",
  color_var = "condition"
)


print(pca_results_1$plot)
```

```{r pca_analysis_2}
#| fig-width: !expr plot_width
#| fig-height: !expr plot_height
#| cache: true

# Optional subsetting for PCA (batch-colored)
se_for_pca_batch <- if (isTRUE(pca_use_interest_only)) {

  keep <- rowData(se_pept_imp_raw)$is_in_scope_for_interest
  keep[is.na(keep)] <- FALSE
  se_pept_imp_raw[keep, , drop = FALSE]

} else {

  se_pept_imp_raw

}

pca_results_2 <- perform_pca_analysis(
  se_for_pca_batch, 
  title_suffix = "- Before Batch Correction\nnon-protein-normalized",
  subtitle = if (isTRUE(pca_use_interest_only)) "PCA on interesting features" else "Visualizing batch effects",
  color_var = "plex"
)

print(pca_results_2$plot)
```

# Batch effect correction with ComBat 

```{r}
#| cache: true

# Perform batch effect correction using ComBat
combat_corrected <- ComBat(
  dat = assay(se_pept_imp_raw),
  batch = experimental_design$plex,
  mod = model.matrix(~ experimental_design$condition)
)

# Create a new SummarizedExperiment with corrected data
se_pept_imp_corrected <- SummarizedExperiment(
  assays = list(counts = combat_corrected),
  colData = experimental_design,
  rowData = rowData(se_pept_imp_raw)
)
```

## PCA Analysis After Batch Correction

```{r pca_after_correction}
#| fig-width: !expr plot_width
#| fig-height: !expr plot_height
#| cache: true

# Optional subsetting for PCA on corrected data
se_corr_for_pca <- if (isTRUE(pca_use_interest_only)) {
  keep <- rowData(se_pept_imp_corrected)$is_in_scope_for_interest
  keep[is.na(keep)] <- FALSE
  se_pept_imp_corrected[keep, , drop = FALSE]
} else {
  se_pept_imp_corrected
}

pca_corrected_condition <- perform_pca_analysis(
  se_corr_for_pca, 
  title_suffix = "- After Batch Correction, non-protein-normalized",
  subtitle = if (isTRUE(pca_use_interest_only)) "PCA on interesting features" else "Visualizing conditions",
  color_var = "condition"
)

print(pca_corrected_condition$plot)
```

```{r batch_effect_correction}
#| fig-width: !expr plot_width
#| fig-height: !expr plot_height
#| cache: true

# Optional subsetting for PCA on corrected data (batch)
se_corr_for_pca_batch <- if (isTRUE(pca_use_interest_only)) {
  keep <- rowData(se_pept_imp_corrected)$is_in_scope_for_interest
  keep[is.na(keep)] <- FALSE
  se_pept_imp_corrected[keep, , drop = FALSE]
} else {
  se_pept_imp_corrected
}

pca_corrected_batch <- perform_pca_analysis(
  se_corr_for_pca_batch, 
  title_suffix = "- After Batch Correction\nnon-protein-normalized",
  subtitle = if (isTRUE(pca_use_interest_only)) "PCA on interesting features" else "Visualizing batch effects",
  color_var = "plex"
)

print(pca_corrected_batch$plot)
```

# Protein-level normalization and SE creation

```{r protein_level_normalization}
#| cache: true
# Build protein-normalized peptide abundances and paired SummarizedExperiment objects
# This enables auditing of peptides excluded by protein-level normalization.

# 1) Build a long peptide table from corrected data with required annotations
#    Use non-log2 (linear) abundances for protein-level normalization
pept_q_raw <- (2 ^ assay(se_pept_imp_corrected)) %>%
  as.data.frame() %>%
  rownames_to_column("nterm_modif_peptide") %>%
  left_join(
    as.data.frame(rowData(se_pept_imp_corrected)) %>%
      dplyr::select(
        nterm_modif_peptide,
        peptide,
        protein,
        nterm_modif,
        specificity
      ),
    by = "nterm_modif_peptide"
  ) %>%
  dplyr::relocate(
    nterm_modif_peptide,
    peptide,
    protein,
    nterm_modif,
    specificity
  )

pept_q_raw_annot <- pept_q_raw %>%
  dplyr::select(
    nterm_modif_peptide,
    peptide,
    protein,
    nterm_modif,
    specificity
  )

# 2) Run peptide-to-protein normalization
#    Using experimental_design as the sample annotation
protein_normalized_peptides <- peptide2protein_normalization(
  peptides = pept_q_raw,
  annot = experimental_design,
  peptide_annot = pept_q_raw_annot,
  summarize_by_specificity = TRUE
)

# 3) Prepare wide matrix of protein-normalized peptide abundances
prot_norm_wide <- protein_normalized_peptides$protein_normalized_pepts_scaled

# Determine which columns correspond to samples
prefixed_cols <- paste0("fraction_int_peptide2prot_", experimental_design$sample)

sample_cols <- intersect(colnames(prot_norm_wide), prefixed_cols)

if (length(sample_cols) == 0) {
  # Fallback: maybe already de-prefixed
  sample_cols <- intersect(colnames(prot_norm_wide), experimental_design$sample)
}

mat_df <- prot_norm_wide %>%
  dplyr::select(nterm_modif_peptide, all_of(sample_cols))

# Remove prefix if present so column names match experimental_design$sample
colnames(mat_df) <- colnames(mat_df) %>%
  stringr::str_remove("^fraction_int_peptide2prot_")

# Convert to matrix and order columns to match design
mat_prot_norm <- mat_df %>%
  column_to_rownames("nterm_modif_peptide") %>%
  as.matrix()

common_samples <- intersect(colnames(mat_prot_norm), experimental_design$sample)

mat_prot_norm <- mat_prot_norm[, common_samples, drop = FALSE]

# Align colData to the matrix columns and set rownames to sample IDs
design_common <- experimental_design %>%
  dplyr::filter(sample %in% common_samples) %>%
  dplyr::arrange(match(sample, common_samples))

rownames(design_common) <- design_common$sample

# Ensure columns strictly follow design order
mat_prot_norm <- mat_prot_norm[, design_common$sample, drop = FALSE]

# 4) Build annotation for protein-normalized rows by merging back rowData
prot_norm_join <- mat_df %>%
  left_join(
    as.data.frame(rowData(se_pept_imp_corrected)),
    by = "nterm_modif_peptide"
  )

rowdata_cols <- setdiff(colnames(prot_norm_join), colnames(mat_df))

annot_prot_norm <- prot_norm_join %>%
  dplyr::select(nterm_modif_peptide, dplyr::all_of(rowdata_cols)) %>%
  distinct()

# Ensure annotation order matches matrix rows
annot_prot_norm <- annot_prot_norm %>%
  dplyr::filter(nterm_modif_peptide %in% rownames(mat_prot_norm)) %>%
  arrange(match(nterm_modif_peptide, rownames(mat_prot_norm))) %>%
  mutate(protein_normalization = "protein_normalized")
  
# Set rownames to match assay rownames
rownames(annot_prot_norm) <- annot_prot_norm$nterm_modif_peptide

# 5) Identify peptides lost by protein-level normalization
all_features <- rownames(assay(se_pept_imp_corrected))
lost_features <- setdiff(all_features, rownames(mat_prot_norm))

n_lost <- length(lost_features)
message("Protein-level normalization: lost ", n_lost, " peptides out of ", length(all_features))

# 6) For lost peptides, bring their original corrected intensities and annotate
quant_lost_df <- assay(se_pept_imp_corrected)[lost_features, , drop = FALSE] %>%
  as.data.frame() %>%
  rownames_to_column("nterm_modif_peptide")

annot_lost <- as.data.frame(rowData(se_pept_imp_corrected)) %>%
  dplyr::filter(nterm_modif_peptide %in% lost_features) %>%
  mutate(protein_normalization = "not_protein_normalized")

# 7) Combine protein-normalized peptides with the lost ones (kept as original corrected intensities)
prot_norm_df <- mat_prot_norm %>%
  as.data.frame() %>%
  rownames_to_column("nterm_modif_peptide")

combined_df <- bind_rows(prot_norm_df, quant_lost_df)

mat_prot_norm_with_lost <- combined_df %>%
  column_to_rownames("nterm_modif_peptide") %>%
  as.matrix()

annot_with_lost <- bind_rows(annot_prot_norm, annot_lost) %>%
  arrange(match(nterm_modif_peptide, rownames(mat_prot_norm_with_lost)))

# Constrain columns to design and set row/col alignment
mat_prot_norm_with_lost <- mat_prot_norm_with_lost[, design_common$sample, drop = FALSE]

rownames(annot_with_lost) <- annot_with_lost$nterm_modif_peptide

# 8) Create SE objects
se_pept_protnorm_pure <- SummarizedExperiment(
  assays = list(counts = mat_prot_norm),
  colData = design_common,
  rowData = annot_prot_norm
)

se_pept_protnorm_with_lost <- SummarizedExperiment(
  assays = list(counts = mat_prot_norm_with_lost),
  colData = design_common,
  rowData = annot_with_lost
)

# Non-protein-normalized SE aligned to the same sample set/order
counts_nonprot <- assay(se_pept_imp_corrected)[, design_common$sample, drop = FALSE]
rowdata_nonprot <- as.data.frame(rowData(se_pept_imp_corrected)) %>%
  mutate(protein_normalization = "none") %>%
  dplyr::filter(nterm_modif_peptide %in% rownames(counts_nonprot)) %>%
  arrange(match(nterm_modif_peptide, rownames(counts_nonprot)))
rownames(rowdata_nonprot) <- rowdata_nonprot$nterm_modif_peptide

se_pept_non_protnorm <- SummarizedExperiment(
  assays = list(counts = counts_nonprot),
  colData = design_common,
  rowData = rowdata_nonprot
)

# Clean up large temporaries
rm(pept_q_raw, pept_q_raw_annot, prot_norm_wide, mat_df, prot_norm_join,
   prot_norm_df, combined_df, quant_lost_df, annot_lost)
   
invisible(gc())
```

# Principal Component Analysis of Protein-Normalized Data

```{r pca_protein_norm_condition}
#| fig-width: !expr plot_width * side_by_side_scale
#| fig-height: !expr plot_height
#| cache: true

# Optional subsetting for PCA on protein-normalized (+ lost)
se_protnorm_for_pca <- if (isTRUE(pca_use_interest_only)) {
  keep <- rowData(se_pept_protnorm_with_lost)$is_in_scope_for_interest
  keep[is.na(keep)] <- FALSE
  se_pept_protnorm_with_lost[keep, , drop = FALSE]
} else {
  se_pept_protnorm_with_lost
}

pca_protnorm_with_lost <- perform_pca_analysis(
  se_protnorm_for_pca,
  title_suffix = "- Protein-normalized (+ lost)",
  subtitle = if (isTRUE(pca_use_interest_only)) "Visualizing conditions - interesting features" else "Visualizing conditions - all features",
  color_var = "condition"
)

# Reuse previously computed PCA for non-protein-normalized data
se_nonprot_for_pca <- if (isTRUE(pca_use_interest_only)) {
  keep <- rowData(se_pept_non_protnorm)$is_in_scope_for_interest
  keep[is.na(keep)] <- FALSE
  se_pept_non_protnorm[keep, , drop = FALSE]
} else {
  se_pept_non_protnorm
}

pca_non_protnorm <- perform_pca_analysis(
  se_nonprot_for_pca, 
  title_suffix = "- Non-protein-normalize\n(after batch correction)",
  subtitle = if (isTRUE(pca_use_interest_only)) "Visualizing conditions - interesting features" else "Visualizing conditions - all features",
  color_var = "condition"
)

ggpubr::ggarrange(
  pca_protnorm_with_lost$plot,
  pca_non_protnorm$plot,
  ncol = 2,
  labels = c("A", "B")
)
```

```{r pca_protein_norm_batch}
#| fig-width: !expr plot_width * side_by_side_scale
#| fig-height: !expr plot_height
#| cache: true

# Optional subsetting for PCA on protein-normalized (+ lost) batch view
se_protnorm_for_pca_batch <- if (isTRUE(pca_use_interest_only)) {
  keep <- rowData(se_pept_protnorm_with_lost)$is_in_scope_for_interest
  keep[is.na(keep)] <- FALSE
  se_pept_protnorm_with_lost[keep, , drop = FALSE]
} else {
  se_pept_protnorm_with_lost
}

pca_protnorm_with_lost_batch <- perform_pca_analysis(
  se_protnorm_for_pca_batch,
  title_suffix = "- Protein-normalized (+ lost)",
  subtitle = if (isTRUE(pca_use_interest_only)) "Visualizing batch effects - interesting features" else "Visualizing batch effects - all features",
  color_var = "plex"
)

# Reuse previously computed PCA for non-protein-normalized data (batch)
se_nonprot_for_pca_batch <- if (isTRUE(pca_use_interest_only)) {
  keep <- rowData(se_pept_non_protnorm)$is_in_scope_for_interest
  keep[is.na(keep)] <- FALSE
  se_pept_non_protnorm[keep, , drop = FALSE]
} else {
  se_pept_non_protnorm
}

pca_non_protnorm_batch <- perform_pca_analysis(
  se_nonprot_for_pca_batch, 
  title_suffix = "- After Batch Correction\nnon-protein-normalized",
  subtitle = if (isTRUE(pca_use_interest_only)) "Visualizing batch effects - interesting features" else "Visualizing batch effects - all features",
  color_var = "plex"
)

ggpubr::ggarrange(
  pca_protnorm_with_lost_batch$plot,
  pca_non_protnorm_batch$plot,
  ncol = 2,
  labels = c("C", "D")
)
```

```{r pca_protein_norm_intersest}
#| fig-width: !expr plot_width * side_by_side_scale
#| fig-height: !expr plot_height
#| cache: true

# Side-by-side PCA: all features vs only interesting features (protein-normalized + lost)
se_all <- se_pept_protnorm_with_lost

# "Interesting" uses the precomputed is_in_scope_for_interest flag
rd <- as.data.frame(rowData(se_all))
keep_int <- rd$is_in_scope_for_interest
keep_int[is.na(keep_int)] <- FALSE

n_int <- sum(keep_int)
if (n_int < 3) {
  message("Not enough interesting features for PCA (n = ", n_int, "). Showing only 'all features'.")
}

# Build SE for interesting features if enough rows
se_int <- if (n_int >= 3) se_all[keep_int, , drop = FALSE] else NULL

# Condition-colored PCAs
p_all_cond <- perform_pca_analysis(
  se_all,
  title_suffix = "- Protein-normalized (+lost) - All features",
  subtitle = "Color: condition",
  color_var = "condition"
)$plot

p_int_cond <- if (!is.null(se_int)) {
  perform_pca_analysis(
    se_int,
    title_suffix = "- Protein-normalized (+lost)\nInteresting features",
    subtitle = "Color: condition",
    color_var = "condition"
  )$plot
} else NULL

# Arrange side-by-side: All vs Interesting
plots_cond <- list(p_all_cond, p_int_cond)

plots_cond <- plots_cond[!vapply(plots_cond, is.null, logical(1))]
if (length(plots_cond) > 0) {
  print(ggpubr::ggarrange(plotlist = plots_cond, ncol = length(plots_cond), labels = c("A", "B")[seq_along(plots_cond)]))
}

```

# Save Results for Downstream Analysis

```{r save_results}
#| cache: true

# Save key objects for downstream analysis
save_objects <- list(
  annotated_df_quant = annotated_df_quant,
  # Keep the batch-corrected raw peptide SE for reference
  se_pept_imp_raw = se_pept_imp_corrected,
  # New objects for protein normalization auditing
  se_pept_protnorm_pure = se_pept_protnorm_pure,
  se_pept_protnorm_with_lost = se_pept_protnorm_with_lost,
  se_pept_non_protnorm = se_pept_non_protnorm,
  lost_features = lost_features,
  experimental_design = experimental_design,
  prot2gene = prot2gene,
  parameters = list(
    search_engine = search_engine,
    sense_protease = sense_protease,
    specificity_protease = specificity_protease,
    organism_annotation = organism_annotation,
    missing_accepted = missing_accepted,
    pre_fix = pre_fix
  )
)

write_rds(save_objects, file.path(rds_dir, "exploratory_results.rds"))

message("Exploratory analysis complete. Results saved for downstream analysis.")
```

# Session Information

```{r session_info}
sessionInfo()
```
